{
  "version": 1,
  "entries": [
    {
      "id": "fail_1766795305015_fffddd6c",
      "timestamp": "2025-12-27T00:28:25.015Z",
      "modelId": "cognitive-engine",
      "category": "tool",
      "tool": "file_glob_search",
      "error": "Tool 'file_glob_search' is not implemented in the agentic loop. Available tools: rag_query, rag_status, rag_index, read_file, list_directory, search_files",
      "errorType": "tool_not_called",
      "context": {
        "query": "{\"pattern\":\"server/src/modules/tooly/status-streamer.ts\"}",
        "queryHash": "ac989090",
        "expectedBehavior": "Tool should be implemented or model should use available tools",
        "actualBehavior": "Tool file_glob_search not found",
        "conversationLength": 1
      },
      "resolved": false,
      "pattern": "TOOL_SUPPRESSION"
    },
    {
      "id": "fail_1766795308334_14ab803a",
      "timestamp": "2025-12-27T00:28:28.334Z",
      "modelId": "cognitive-engine",
      "category": "tool",
      "tool": "ls",
      "error": "Tool 'ls' is not implemented in the agentic loop. Available tools: rag_query, rag_status, rag_index, read_file, list_directory, search_files",
      "errorType": "tool_not_called",
      "context": {
        "query": "{\"dirPath\":\"server/src/modules/tooly\"}",
        "queryHash": "ac989090",
        "expectedBehavior": "Tool should be implemented or model should use available tools",
        "actualBehavior": "Tool ls not found",
        "conversationLength": 1
      },
      "resolved": false,
      "pattern": "TOOL_SUPPRESSION"
    },
    {
      "id": "fail_1766795309267_2590254c",
      "timestamp": "2025-12-27T00:28:29.267Z",
      "modelId": "cognitive-engine",
      "category": "tool",
      "tool": "file_glob_search",
      "error": "Tool 'file_glob_search' is not implemented in the agentic loop. Available tools: rag_query, rag_status, rag_index, read_file, list_directory, search_files",
      "errorType": "tool_not_called",
      "context": {
        "query": "{\"pattern\":\"**/status-streamer.ts\"}",
        "queryHash": "ac989090",
        "expectedBehavior": "Tool should be implemented or model should use available tools",
        "actualBehavior": "Tool file_glob_search not found",
        "conversationLength": 1
      },
      "resolved": false,
      "pattern": "TOOL_SUPPRESSION"
    },
    {
      "id": "fail_1766795313121_896aef38",
      "timestamp": "2025-12-27T00:28:33.121Z",
      "modelId": "cognitive-engine",
      "category": "tool",
      "tool": "file_glob_search",
      "error": "Tool 'file_glob_search' is not implemented in the agentic loop. Available tools: rag_query, rag_status, rag_index, read_file, list_directory, search_files",
      "errorType": "tool_not_called",
      "context": {
        "query": "{\"pattern\":\"status-streamer*\"}",
        "queryHash": "ac989090",
        "expectedBehavior": "Tool should be implemented or model should use available tools",
        "actualBehavior": "Tool file_glob_search not found",
        "conversationLength": 1
      },
      "resolved": false,
      "pattern": "TOOL_SUPPRESSION"
    },
    {
      "id": "fail_1766796451502_1c623db1",
      "timestamp": "2025-12-27T00:47:31.502Z",
      "modelId": "cognitive-engine",
      "category": "tool",
      "tool": "extra_tools_git_status",
      "error": "Tool 'extra_tools_git_status' is not implemented in the agentic loop. Available tools: rag_query, rag_status, rag_index, read_file, list_directory, search_files",
      "errorType": "tool_not_called",
      "context": {
        "query": "{}",
        "queryHash": "99914b93",
        "expectedBehavior": "Tool should be implemented or model should use available tools",
        "actualBehavior": "Tool extra_tools_git_status not found",
        "conversationLength": 1
      },
      "resolved": false,
      "pattern": "TOOL_SUPPRESSION"
    },
    {
      "id": "fail_1766796885273_a86c7874",
      "timestamp": "2025-12-27T00:54:45.273Z",
      "modelId": "cognitive-engine",
      "category": "tool",
      "tool": "extra_tools_git_status",
      "error": "Tool 'extra_tools_git_status' is not implemented in the agentic loop. Available tools: rag_query, rag_status, rag_index, read_file, list_directory, search_files",
      "errorType": "tool_not_called",
      "context": {
        "query": "{}",
        "queryHash": "99914b93",
        "expectedBehavior": "Tool should be implemented or model should use available tools",
        "actualBehavior": "Tool extra_tools_git_status not found",
        "conversationLength": 1
      },
      "resolved": false,
      "pattern": "TOOL_SUPPRESSION"
    },
    {
      "id": "fail_1766798135160_8513b692",
      "timestamp": "2025-12-27T01:15:35.160Z",
      "modelId": "cognitive-engine",
      "category": "tool",
      "tool": "create_rule_block",
      "error": "Tool 'create_rule_block' not available. Tried agentic loop and continue-tools server. Error: Request failed with status code 404",
      "errorType": "tool_not_called",
      "context": {
        "query": "{\"name\":\"StreamingFixes\",\"rule\":\"Ensure SSE headers are set in `StatusStreamer` and frontend uses `EventSource` for real-time updates.\",\"description\":\"Apply fixes to ensure streaming works properly in VS Code by setting correct SSE headers and enabling EventSource-based listening.\",\"alwaysApply\":true}",
        "queryHash": "f816f07e",
        "expectedBehavior": "Tool should be available in agentic loop or MCP server",
        "actualBehavior": "Tool create_rule_block not found anywhere",
        "conversationLength": 1
      },
      "resolved": false,
      "pattern": "TOOL_SUPPRESSION"
    },
    {
      "id": "fail_1766798135165_ca3b1923",
      "timestamp": "2025-12-27T01:15:35.165Z",
      "modelId": "cognitive-engine",
      "category": "tool",
      "tool": "edit_file",
      "error": "Tool 'edit_file' not available. Tried agentic loop and continue-tools server. Error: Request failed with status code 404",
      "errorType": "tool_not_called",
      "context": {
        "query": "{\"filepath\":\"server/src/modules/tooly/status-streamer.ts\"}",
        "queryHash": "ac989090",
        "expectedBehavior": "Tool should be available in agentic loop or MCP server",
        "actualBehavior": "Tool edit_file not found anywhere",
        "conversationLength": 1
      },
      "resolved": false,
      "pattern": "TOOL_SUPPRESSION"
    },
    {
      "id": "fail_1766798227675_32c00b15",
      "timestamp": "2025-12-27T01:17:07.675Z",
      "modelId": "cognitive-engine",
      "category": "tool",
      "tool": "create_new_file",
      "error": "Tool 'create_new_file' not available. Tried agentic loop and continue-tools server. Error: Request failed with status code 404",
      "errorType": "tool_not_called",
      "context": {
        "query": "{\"filepath\":\"server/src/modules/tooly/status-streamer.ts.fixed\",\"contents\":\"# Updated StatusStreamer for SSE Streaming Support\\n// Ensures proper streaming headers and EventSource compatibility in VS Code\\n\\nimport { Response } from 'express';\\n\\nexport interface StatusMessage {\\n  type: 'thinking' | 'tool_start' | 'tool_complete' | 'tool_error' | 'retry' | 'info';\\n  message: string;\\n  tool?: string;\\n  progress?: number; // 0-100\\n  metadata?: any;\\n}\\n\\nexport class StatusStreamer {\\n  private res: Response;\\n  private enabled: boolean;\\n  private messageCount: number = 0;\\n\\n  constructor(res: Response, enabled: boolean = true) {\\n    this.res = res;\\n    this.enabled = enabled;\\n    \\n    if (enabled) {\\n      // ✅ Ensure SSE headers are set for VS Code streaming\\n      res.setHeader('Content-Type', 'text/event-stream');\\n      res.setHeader('Cache-Control', 'no-cache');\\n      res.setHeader('Connection', 'keep-alive');\\n    }\\n  }\\n\\n  /** Send a status message to the IDE */\\n  sendStatus(status: StatusMessage): void {\\n    if (!this.enabled) return;\\n\\n    const icon = STATUS_ICONS[status.type] || ''; // Fallback for unknown types\\n    const content = `\\n${icon} ${status.message}\\n`;\\n\\n    this.sendChunk({\\n      id: `status-${++this.messageCount}`,\\n      object: 'chat.completion.chunk',\\n      choices: [{\\n        index: 0,\\n        delta: { content },\\n        finish_reason: null\\n      }]\\n    });\\n  }\\n\\n  /** Send thinking status */\\n  thinking(message: string = 'Analyzing request...'): void {\\n    this.sendStatus({\\n      type: 'thinking',\\n      message\\n    });\\n  }\\n\\n  /** Send tool start status */\\n  toolStart(tool: string, args?: any): void {\\n    const argsPreview = args ? ` (${this.formatArgs(args)})` : '';\\n    this.sendStatus({\\n      type: 'tool_start',\\n      message: `Executing: ${tool}${argsPreview}`,\\n      tool\\n    });\\n  }\\n\\n  /** Send tool complete status */\\n  toolComplete(tool: string, durationMs?: number): void {\\n    const duration = durationMs ? ` (${durationMs}ms)` : '';\\n    this.sendStatus({\\n      type: 'tool_complete',\\n      message: `${tool} complete${duration}`,\\n      tool\\n    });\\n  }\\n\\n  /** Send tool error status */\\n  toolError(tool: string, error: string): void {\\n    this.sendStatus({\\n      type: 'tool_error',\\n      message: `${tool} failed: ${error}`,\\n      tool\\n    });\\n  }\\n\\n  /** Send retry status */\\n  retry(attempt: number, maxAttempts: number, delayMs: number): void {\\n    this.sendStatus({\\n      type: 'retry',\\n      message: `Retrying... (attempt ${attempt}/${maxAttempts}, waiting ${Math.round(delayMs/1000)}s)`\\n    });\\n  }\\n\\n  /** Send info status */\\n  info(message: string): void {\\n    this.sendStatus({\\n      type: 'info',\\n      message\\n    });\\n  }\\n\\n  /** Send a raw SSE chunk (for debugging or custom updates) */\\n  sendChunk(chunk: any): void {\\n    if (!this.enabled || !this.res.headersSent) return;\\n\\n    try {\\n      this.res.write(`data: ${JSON.stringify(chunk)}\\n\\\\n`);\\n    } catch (e) {\\n      // Handle closed connection gracefully\\n      console.warn('Failed to send chunk:', e.message);\\n    }\\n  }\\n\\n  /** Stream a response from the LLM */\\n  async streamResponse(responseStream: AsyncIterable<Buffer> | NodeJS.ReadableStream): Promise<string> {\\n    let fullContent = '';\\n\\n    if (Symbol.asyncIterator in responseStream) {\\n      // Async iterator\\n      for await (const chunk of responseStream as AsyncIterable<Buffer>) {\\n        const chunkStr = chunk.toString();\\n        fullContent += chunkStr;\\n        this.res.write(chunkStr);\\n      }\\n    } else {\\n      // Node stream\\n      const stream = responseStream as NodeJS.ReadableStream;\\n      return new Promise((resolve, reject) => {\\n        stream.on('data', (chunk: Buffer) => {\\n          const chunkStr = chunk.toString();\\n          fullContent += chunkStr;\\n          this.res.write(chunkStr);\\n        });\\n        stream.on('end', () => resolve(fullContent));\\n        stream.on('error', reject);\\n      });\\n    }\\n\\n    return fullContent;\\n  }\\n\\n  /** End the stream */\\n  end(): void {\\n    if (!this.enabled) return;\\n\\n    try {\\n      this.res.write('data: [DONE]\\\\n\\\\n');\\n      this.res.end();\\n    } catch (e) {\\n      // Handle closed connection gracefully\\n      console.warn('Failed to end stream:', e.message);\\n    }\\n  }\\n\\n  /** Send error and end */\\n  sendError(message: string): void {\\n    this.sendStatus({\\n      type: 'tool_error',\\n      message\\n    });\\n    this.end();\\n  }\\n\\n  /** Format tool arguments for display */\\n  private formatArgs(args: any): string {\\n    if (!args || typeof args !== 'object') return '';\\n\\n    const entries = Object.entries(args);\\n    if (entries.length === 0) return '';\\n\\n    return entries\\n      .map(([key, value]) => {\\n        const strValue = String(value);\\n        const truncated = strValue.length > 30 ? strValue.slice(0, 30) + '...' : strValue;\\n        return `${key}: ${truncated}`;\\n      })\\n      .join(', ');\\n  }\\n\\n  /** Check if streaming is enabled */\\n  isEnabled(): boolean {\\n    return this.enabled;\\n  }\\n}\"}",
        "queryHash": "8a9ad2c3",
        "expectedBehavior": "Tool should be available in agentic loop or MCP server",
        "actualBehavior": "Tool create_new_file not found anywhere",
        "conversationLength": 1
      },
      "resolved": false,
      "pattern": "TOOL_SUPPRESSION"
    },
    {
      "id": "fail_1766798232513_d739d476",
      "timestamp": "2025-12-27T01:17:12.513Z",
      "modelId": "cognitive-engine",
      "category": "tool",
      "tool": "run_terminal_command",
      "error": "Tool 'run_terminal_command' not available. Tried agentic loop and continue-tools server. Error: Request failed with status code 404",
      "errorType": "tool_not_called",
      "context": {
        "query": "{\"command\":\"cd server && cp src/modules/tooly/status-streamer.ts.fixed src/modules/tooly/status-streamer.ts\",\"waitForCompletion\":true}",
        "queryHash": "2680a1dd",
        "expectedBehavior": "Tool should be available in agentic loop or MCP server",
        "actualBehavior": "Tool run_terminal_command not found anywhere",
        "conversationLength": 1
      },
      "resolved": false,
      "pattern": "TOOL_SUPPRESSION"
    },
    {
      "id": "fail_1766798239706_49e24a32",
      "timestamp": "2025-12-27T01:17:19.706Z",
      "modelId": "cognitive-engine",
      "category": "tool",
      "tool": "create_rule_block",
      "error": "Tool 'create_rule_block' not available. Tried agentic loop and continue-tools server. Error: Request failed with status code 404",
      "errorType": "tool_not_called",
      "context": {
        "query": "{\"name\":\"StreamingFixes\",\"rule\":\"Ensure SSE headers are set in `StatusStreamer` and frontend uses `EventSource` for real-time updates. Update the backend to include proper error handling for closed connections.\",\"description\":\"Apply fixes to ensure streaming works properly in VS Code by setting correct SSE headers, improving error handling, and ensuring non-blocking tool execution.\"}",
        "queryHash": "b33e4605",
        "expectedBehavior": "Tool should be available in agentic loop or MCP server",
        "actualBehavior": "Tool create_rule_block not found anywhere",
        "conversationLength": 1
      },
      "resolved": false,
      "pattern": "TOOL_SUPPRESSION"
    },
    {
      "id": "fail_1766798343419_03a8a155",
      "timestamp": "2025-12-27T01:19:03.419Z",
      "modelId": "cognitive-engine",
      "category": "tool",
      "tool": "create_new_file",
      "error": "Tool 'create_new_file' not available. Tried agentic loop and continue-tools server. Error: Request failed with status code 404",
      "errorType": "tool_not_called",
      "context": {
        "query": "{\"filepath\":\"server/src/modules/tooly/status-streamer.ts\",\"contents\":\"# Updated StatusStreamer for SSE Streaming Support\\n// Ensures proper streaming headers and EventSource compatibility in VS Code\\n\\nimport { Response } from 'express';\\n\\nexport interface StatusMessage {\\n  type: 'thinking' | 'tool_start' | 'tool_complete' | 'tool_error' | 'retry' | 'info';\\n  message: string;\\n  tool?: string;\\n  progress?: number; // 0-100\\n  metadata?: any;\\n}\\n\\nexport class StatusStreamer {\\n  private res: Response;\\n  private enabled: boolean;\\n  private messageCount: number = 0;\\n\\n  constructor(res: Response, enabled: boolean = true) {\\n    this.res = res;\\n    this.enabled = enabled;\\n    \\n    if (enabled) {\\n      // ✅ Ensure SSE headers are set for VS Code streaming\\n      res.setHeader('Content-Type', 'text/event-stream');\\n      res.setHeader('Cache-Control', 'no-cache');\\n      res.setHeader('Connection', 'keep-alive');\\n    }\\n  }\\n\\n  /** Send a status message to the IDE */\\n  sendStatus(status: StatusMessage): void {\\n    if (!this.enabled) return;\\n\\n    const icon = STATUS_ICONS[status.type] || ''; // Fallback for unknown types\\n    const content = `\\n${icon} ${status.message}\\n`;\\n\\n    this.sendChunk({\\n      id: `status-${++this.messageCount}`,\\n      object: 'chat.completion.chunk',\\n      choices: [{\\n        index: 0,\\n        delta: { content },\\n        finish_reason: null\\n      }]\\n    });\\n  }\\n\\n  /** Send thinking status */\\n  thinking(message: string = 'Analyzing request...'): void {\\n    this.sendStatus({\\n      type: 'thinking',\\n      message\\n    });\\n  }\\n\\n  /** Send tool start status */\\n  toolStart(tool: string, args?: any): void {\\n    const argsPreview = args ? ` (${this.formatArgs(args)})` : '';\\n    this.sendStatus({\\n      type: 'tool_start',\\n      message: `Executing: ${tool}${argsPreview}`,\\n      tool\\n    });\\n  }\\n\\n  /** Send tool complete status */\\n  toolComplete(tool: string, durationMs?: number): void {\\n    const duration = durationMs ? ` (${durationMs}ms)` : '';\\n    this.sendStatus({\\n      type: 'tool_complete',\\n      message: `${tool} complete${duration}`,\\n      tool\\n    });\\n  }\\n\\n  /** Send tool error status */\\n  toolError(tool: string, error: string): void {\\n    this.sendStatus({\\n      type: 'tool_error',\\n      message: `${tool} failed: ${error}`,\\n      tool\\n    });\\n  }\\n\\n  /** Send retry status */\\n  retry(attempt: number, maxAttempts: number, delayMs: number): void {\\n    this.sendStatus({\\n      type: 'retry',\\n      message: `Retrying... (attempt ${attempt}/${maxAttempts}, waiting ${Math.round(delayMs/1000)}s)`\\n    });\\n  }\\n\\n  /** Send info status */\\n  info(message: string): void {\\n    this.sendStatus({\\n      type: 'info',\\n      message\\n    });\\n  }\\n\\n  /** Send a raw SSE chunk (for debugging or custom updates) */\\n  sendChunk(chunk: any): void {\\n    if (!this.enabled || !this.res.headersSent) return;\\n\\n    try {\\n      this.res.write(`data: ${JSON.stringify(chunk)}\\n\\\\n`);\\n    } catch (e) {\\n      // Handle closed connection gracefully\\n      console.warn('Failed to send chunk:', e.message);\\n    }\\n  }\\n\\n  /** Stream a response from the LLM */\\n  async streamResponse(responseStream: AsyncIterable<Buffer> | NodeJS.ReadableStream): Promise<string> {\\n    let fullContent = '';\\n\\n    if (Symbol.asyncIterator in responseStream) {\\n      // Async iterator\\n      for await (const chunk of responseStream as AsyncIterable<Buffer>) {\\n        const chunkStr = chunk.toString();\\n        fullContent += chunkStr;\\n        this.res.write(chunkStr);\\n      }\\n    } else {\\n      // Node stream\\n      const stream = responseStream as NodeJS.ReadableStream;\\n      return new Promise((resolve, reject) => {\\n        stream.on('data', (chunk: Buffer) => {\\n          const chunkStr = chunk.toString();\\n          fullContent += chunkStr;\\n          this.res.write(chunkStr);\\n        });\\n        stream.on('end', () => resolve(fullContent));\\n        stream.on('error', reject);\\n      });\\n    }\\n\\n    return fullContent;\\n  }\\n\\n  /** End the stream */\\n  end(): void {\\n    if (!this.enabled) return;\\n\\n    try {\\n      this.res.write('data: [DONE]\\\\n\\\\n');\\n      this.res.end();\\n    } catch (e) {\\n      // Handle closed connection gracefully\\n      console.warn('Failed to end stream:', e.message);\\n    }\\n  }\\n\\n  /** Send error and end */\\n  sendError(message: string): void {\\n    this.sendStatus({\\n      type: 'tool_error',\\n      message\\n    });\\n    this.end();\\n  }\\n\\n  /** Format tool arguments for display */\\n  private formatArgs(args: any): string {\\n    if (!args || typeof args !== 'object') return '';\\n\\n    const entries = Object.entries(args);\\n    if (entries.length === 0) return '';\\n\\n    return entries\\n      .map(([key, value]) => {\\n        const strValue = String(value);\\n        const truncated = strValue.length > 30 ? strValue.slice(0, 30) + '...' : strValue;\\n        return `${key}: ${truncated}`;\\n      })\\n      .join(', ');\\n  }\\n\\n  /** Check if streaming is enabled */\\n  isEnabled(): boolean {\\n    return this.enabled;\\n  }\\n}\"}",
        "queryHash": "8a9ad2c3",
        "expectedBehavior": "Tool should be available in agentic loop or MCP server",
        "actualBehavior": "Tool create_new_file not found anywhere",
        "conversationLength": 1
      },
      "resolved": false,
      "pattern": "TOOL_SUPPRESSION"
    },
    {
      "id": "fail_1766798346352_95cb471b",
      "timestamp": "2025-12-27T01:19:06.352Z",
      "modelId": "cognitive-engine",
      "category": "tool",
      "tool": "run_terminal_command",
      "error": "Tool 'run_terminal_command' not available. Tried agentic loop and continue-tools server. Error: Request failed with status code 404",
      "errorType": "tool_not_called",
      "context": {
        "query": "{\"command\":\"cd server && mv src/modules/tooly/status-streamer.ts.fixed src/modules/tooly/status-streamer.ts\",\"waitForCompletion\":true}",
        "queryHash": "2680a1dd",
        "expectedBehavior": "Tool should be available in agentic loop or MCP server",
        "actualBehavior": "Tool run_terminal_command not found anywhere",
        "conversationLength": 1
      },
      "resolved": false,
      "pattern": "TOOL_SUPPRESSION"
    },
    {
      "id": "fail_1766798350941_ddb225ea",
      "timestamp": "2025-12-27T01:19:10.941Z",
      "modelId": "cognitive-engine",
      "category": "tool",
      "tool": "create_rule_block",
      "error": "Tool 'create_rule_block' not available. Tried agentic loop and continue-tools server. Error: Request failed with status code 404",
      "errorType": "tool_not_called",
      "context": {
        "query": "{\"name\":\"StreamingFixes\",\"rule\":\"Update the backend to ensure SSE headers are set and handle closed connections gracefully in `StatusStreamer`.\",\"description\":\"Apply these changes to fix streaming issues by ensuring proper SSE headers are set, improving error handling for closed connections, and maintaining non-blocking tool execution.\"}",
        "queryHash": "b33e4605",
        "expectedBehavior": "Tool should be available in agentic loop or MCP server",
        "actualBehavior": "Tool create_rule_block not found anywhere",
        "conversationLength": 1
      },
      "resolved": false,
      "pattern": "TOOL_SUPPRESSION"
    },
    {
      "id": "fail_1766798510288_ad0d60fc",
      "timestamp": "2025-12-27T01:21:50.288Z",
      "modelId": "cognitive-engine",
      "category": "tool",
      "tool": "create_new_file",
      "error": "Tool 'create_new_file' not available. Tried agentic loop and continue-tools server. Error: Request failed with status code 404",
      "errorType": "tool_not_called",
      "context": {
        "query": "{\"filepath\":\"server/src/modules/tooly/streaming-middleware.ts\",\"contents\":\"#!/usr/bin/env node\\n// Streaming Middleware for Non-Blocking SSE from Backend to IDE\\n\\nexport async function setupStreamingMiddleware(res: any, isStreaming: boolean = true) {\\n    // Set SSE headers if streaming is enabled\\n    if (isStreaming) {\\n        res.setHeader('Content-Type', 'text/event-stream');\\n        res.setHeader('Cache-Control', 'no-cache');\\n        res.setHeader('Connection', 'keep-alive');\\n    }\\n}\\n\\n// Helper function to send SSE chunks safely\\nfunction safeSendChunk(res: any, chunk: string) {\\n    try {\\n        if (!res.headersSent) {\\n            res.write(`data: ${chunk}\\n\\n`);\\n        }\\n    } catch (error) {\\n        console.warn('Failed to send chunk:', error.message);\\n    }\\n}\\n\\n// Helper function for streaming errors\\nfunction safeEndStream(res: any, message?: string) {\\n    try {\\n        if (!res.headersSent) {\\n            res.write(`data: [ERROR] ${message || 'Stream ended'}\\n\\n`);\\n            res.end();\\n        }\\n    } catch (error) {\\n        console.error('Failed to end stream:', error.message);\\n    }\\n}\"}",
        "queryHash": "35a987bf",
        "expectedBehavior": "Tool should be available in agentic loop or MCP server",
        "actualBehavior": "Tool create_new_file not found anywhere",
        "conversationLength": 1
      },
      "resolved": false,
      "pattern": "TOOL_SUPPRESSION"
    },
    {
      "id": "fail_1766798548425_d8cd9145",
      "timestamp": "2025-12-27T01:22:28.425Z",
      "modelId": "cognitive-engine",
      "category": "tool",
      "tool": "create_new_file",
      "error": "Tool 'create_new_file' not available. Tried agentic loop and continue-tools server. Error: Request failed with status code 404",
      "errorType": "tool_not_called",
      "context": {
        "query": "{\"filepath\":\"server/src/modules/tooly/streaming-middleware.ts\",\"contents\":\"#!/usr/bin/env node\\n// Enhanced Streaming Middleware for Non-Blocking SSE from Backend to IDE\\n\\nexport class StreamMiddleware {\\n  private res: any;\\n  private isStreaming: boolean;\\n  \\n  constructor(res: any, isStreaming: boolean = true) {\\n    this.res = res;\\n    this.isStreaming = isStreaming;\\n    \\n    // Set SSE headers if streaming is enabled\\n    if (this.isStreaming) {\\n      this.res.setHeader('Content-Type', 'text/event-stream');\\n      this.res.setHeader('Cache-Control', 'no-cache');\\n      this.res.setHeader('Connection', 'keep-alive');\\n    }\\n  }\\n  \\n  // Send a chunk of data safely\\n  sendChunk(chunk: string): void {\\n    try {\\n      if (!this.res.headersSent) {\\n        this.res.write(`data: ${JSON.stringify(chunk)}\\n\\n`);\\n      }\\n    } catch (error) {\\n      console.error('Failed to send chunk:', error.message);\\n    }\\n  }\\n  \\n  // End the stream gracefully\\n  endStream(message?: string): void {\\n    try {\\n      if (!this.res.headersSent) {\\n        this.res.write(`data: [DONE] ${message || 'Stream ended'}\\n\\n`);\\n        this.res.end();\\n      }\\n    } catch (error) {\\n      console.error('Failed to end stream:', error.message);\\n    }\\n  }\\n  \\n  // Send an error safely\\n  sendError(message: string): void {\\n    try {\\n      if (!this.res.headersSent) {\\n        this.sendChunk({ type: 'error', message });\\n        this.endStream();\\n      }\\n    } catch (error) {\\n      console.error('Failed to send error:', error.message);\\n    }\\n  }\\n}\\n\\n// Example usage in a tool execution function:\\nexport async function executeToolWithStreaming(toolName: string, args?: any, res: any): Promise<void> {\\n  const streamer = new StreamMiddleware(res, true);\\n  \\n  try {\\n    // Simulate tool execution\\n    console.log(`Executing ${toolName}...`);\\n    streamer.sendChunk({ status: 'thinking', message: `Running ${toolName}` });\\n    \\n    await new Promise(resolve => setTimeout(resolve, 2000)); // Simulate delay\\n    streamer.sendChunk({ status: 'complete', content: `Result for ${toolName}: Success!` });\\n    \\n    streamer.endStream();\\n  } catch (error) {\\n    console.error('Tool execution failed:', error.message);\\n    streamer.sendError(error.message);\\n  }\\n}\"}",
        "queryHash": "b0f9fc32",
        "expectedBehavior": "Tool should be available in agentic loop or MCP server",
        "actualBehavior": "Tool create_new_file not found anywhere",
        "conversationLength": 1
      },
      "resolved": false,
      "pattern": "TOOL_SUPPRESSION"
    },
    {
      "id": "fail_1766798582219_32211645",
      "timestamp": "2025-12-27T01:23:02.219Z",
      "modelId": "cognitive-engine",
      "category": "tool",
      "tool": "create_new_file",
      "error": "Tool 'create_new_file' not available. Tried agentic loop and continue-tools server. Error: Request failed with status code 404",
      "errorType": "tool_not_called",
      "context": {
        "query": "{\"filepath\":\"server/src/modules/tooly/streaming-middleware.ts\",\"contents\":\"// Enhanced Streaming Middleware for Non-Blocking SSE from Backend to IDE\\n//\\nexport class StreamMiddleware {\\n  private res: any;\\n  private isStreaming: boolean;\\n  \\n  constructor(res: any, isStreaming: boolean = true) {\\n    this.res = res;\\n    this.isStreaming = isStreaming;\\n    \\n    // Set SSE headers if streaming is enabled\\n    if (this.isStreaming) {\\n      res.setHeader('Content-Type', 'text/event-stream');\\n      res.setHeader('Cache-Control', 'no-cache');\\n      res.setHeader('Connection', 'keep-alive');\\n    }\\n  }\\n  \\n  // Send a chunk of data safely\\n  sendChunk(chunk: any): void {\\n    try {\\n      if (!this.res.headersSent) {\\n        this.res.write(`data: ${JSON.stringify(chunk)}\\n\\n`);\\n      }\\n    } catch (error) {\\n      console.error('Failed to send chunk:', error.message);\\n    }\\n  }\\n  \\n  // End the stream gracefully\\n  endStream(message?: string): void {\\n    try {\\n      if (!this.res.headersSent) {\\n        this.res.write(`data: [DONE] ${message || 'Stream ended'}\\n\\n`);\\n        this.res.end();\\n      }\\n    } catch (error) {\\n      console.error('Failed to end stream:', error.message);\\n    }\\n  }\\n  \\n  // Send an error safely\\n  sendError(message: string): void {\\n    try {\\n      if (!this.res.headersSent) {\\n        this.sendChunk({ type: 'error', message });\\n        this.endStream();\\n      }\\n    } catch (error) {\\n      console.error('Failed to send error:', error.message);\\n    }\\n  }\\n}\\n\\n// Example usage in middleware:\\nexport async function setupMiddleware(res: any, isStreaming: boolean = true): void {\\n  const streamer = new StreamMiddleware(res, isStreaming);\\n  \\n  // Simulate streaming data (e.g., tool execution)\\n  streamer.sendChunk({ status: 'thinking', message: 'Processing request...' });\\n  await new Promise(resolve => setTimeout(resolve, 1000)); // Simulate delay\\n  streamer.sendChunk({ status: 'complete', content: 'Result received!' });\\n  streamer.endStream();\\n}\"}",
        "queryHash": "6abbc926",
        "expectedBehavior": "Tool should be available in agentic loop or MCP server",
        "actualBehavior": "Tool create_new_file not found anywhere",
        "conversationLength": 1
      },
      "resolved": false,
      "pattern": "TOOL_SUPPRESSION"
    },
    {
      "id": "fail_1766798616625_bea1a3e4",
      "timestamp": "2025-12-27T01:23:36.625Z",
      "modelId": "cognitive-engine",
      "category": "tool",
      "tool": "create_new_file",
      "error": "Tool 'create_new_file' not available. Tried agentic loop and continue-tools server. Error: Request failed with status code 404",
      "errorType": "tool_not_called",
      "context": {
        "query": "{\"filepath\":\"server/src/modules/tooly/streaming-middleware.ts\",\"contents\":\"// Enhanced Streaming Middleware for Non-Blocking SSE from Backend to IDE\\n//\\nexport class StreamMiddleware {\\n  private res: any;\\n  private isStreaming: boolean;\\n  \\n  constructor(res: any, isStreaming: boolean = true) {\\n    this.res = res;\\n    this.isStreaming = isStreaming;\\n    \\n    // Set SSE headers if streaming is enabled\\n    if (this.isStreaming) {\\n      res.setHeader('Content-Type', 'text/event-stream');\\n      res.setHeader('Cache-Control', 'no-cache');\\n      res.setHeader('Connection', 'keep-alive');\\n    }\\n  }\\n  \\n  // Send a chunk of data safely\\n  sendChunk(chunk: any): void {\\n    try {\\n      if (!this.res.headersSent) {\\n        this.res.write(`data: ${JSON.stringify(chunk)}\\n\\n`);\\n      }\\n    } catch (error) {\\n      console.error('Failed to send chunk:', error.message);\\n    }\\n  }\\n  \\n  // End the stream gracefully\\n  endStream(message?: string): void {\\n    try {\\n      if (!this.res.headersSent) {\\n        this.res.write(`data: [DONE] ${message || 'Stream ended'}\\n\\n`);\\n        this.res.end();\\n      }\\n    } catch (error) {\\n      console.error('Failed to end stream:', error.message);\\n    }\\n  }\\n  \\n  // Send an error safely\\n  sendError(message: string): void {\\n    try {\\n      if (!this.res.headersSent) {\\n        this.sendChunk({ type: 'error', message });\\n        this.endStream();\\n      }\\n    } catch (error) {\\n      console.error('Failed to send error:', error.message);\\n    }\\n  }\\n}\\n\\n// Example middleware integration:\\nexport async function handleToolExecution(res: any, isStreaming: boolean = true): Promise<void> {\\n  const streamer = new StreamMiddleware(res, isStreaming);\\n  \\n  // Simulate tool execution with streaming updates\\n  streamer.sendChunk({ status: 'thinking', message: 'Starting tool...' });\\n  await new Promise(resolve => setTimeout(resolve, 1000)); // Simulate delay\\n  streamer.sendChunk({ status: 'complete', content: 'Tool executed successfully!' });\\n  \\n  streamer.endStream();\\n}\"}",
        "queryHash": "93ce74bd",
        "expectedBehavior": "Tool should be available in agentic loop or MCP server",
        "actualBehavior": "Tool create_new_file not found anywhere",
        "conversationLength": 1
      },
      "resolved": false,
      "pattern": "TOOL_SUPPRESSION"
    },
    {
      "id": "fail_1766798652709_d9e9c379",
      "timestamp": "2025-12-27T01:24:12.709Z",
      "modelId": "cognitive-engine",
      "category": "tool",
      "tool": "create_new_file",
      "error": "Tool 'create_new_file' not available. Tried agentic loop and continue-tools server. Error: Request failed with status code 404",
      "errorType": "tool_not_called",
      "context": {
        "query": "{\"filepath\":\"server/src/modules/tooly/streaming-middleware.ts\",\"contents\":\"// Enhanced Streaming Middleware for Non-Blocking SSE from Backend to IDE\\n//\\nexport class StreamMiddleware {\\n  private res: any;\\n  private isStreamingEnabled: boolean = true;\\n  \\n  constructor(res: any, isStreamingEnabled: boolean = true) {\\n    this.res = res;\\n    this.isStreamingEnabled = isStreamingEnabled;\\n    \\n    // Set SSE headers if streaming is enabled\\n    if (this.isStreamingEnabled) {\\n      res.setHeader('Content-Type', 'text/event-stream');\\n      res.setHeader('Cache-Control', 'no-cache');\\n      res.setHeader('Connection', 'keep-alive');\\n    }\\n  }\\n  \\n  // Send a chunk of data safely\\n  sendChunk(chunk: any): void {\\n    try {\\n      if (!this.res.headersSent) {\\n        this.res.write(`data: ${JSON.stringify(chunk)}\\n\\n`);\\n      }\\n    } catch (error) {\\n      console.error('Failed to send chunk:', error.message);\\n    }\\n  }\\n  \\n  // End the stream gracefully\\n  endStream(message?: string): void {\\n    try {\\n      if (!this.res.headersSent) {\\n        this.res.write(`data: [DONE] ${message || 'Stream ended'}\\n\\n`);\\n        this.res.end();\\n      }\\n    } catch (error) {\\n      console.error('Failed to end stream:', error.message);\\n    }\\n  }\\n  \\n  // Send an error safely\\n  sendError(message: string): void {\\n    try {\\n      if (!this.res.headersSent) {\\n        this.sendChunk({ type: 'error', message });\\n        this.endStream();\\n      }\\n    } catch (error) {\\n      console.error('Failed to send error:', error.message);\\n    }\\n  }\\n}\\n\\n// Example middleware integration for tool execution:\\nexport async function executeToolWithStreaming(res: any, isStreamingEnabled: boolean = true): Promise<void> {\\n  const streamer = new StreamMiddleware(res, isStreamingEnabled);\\n  \\n  // Simulate a tool execution with streaming updates\\n  streamer.sendChunk({ status: 'thinking', message: 'Processing request...' });\\n  await new Promise(resolve => setTimeout(resolve, 1000)); // Simulate delay\\n  streamer.sendChunk({ status: 'complete', content: 'Tool result received!' });\\n  \\n  streamer.endStream();\\n}\"}",
        "queryHash": "45e47fb3",
        "expectedBehavior": "Tool should be available in agentic loop or MCP server",
        "actualBehavior": "Tool create_new_file not found anywhere",
        "conversationLength": 1
      },
      "resolved": false,
      "pattern": "TOOL_SUPPRESSION"
    },
    {
      "id": "fail_1766798690199_01ea03fc",
      "timestamp": "2025-12-27T01:24:50.199Z",
      "modelId": "cognitive-engine",
      "category": "tool",
      "tool": "create_rule_block",
      "error": "Tool 'create_rule_block' not available. Tried agentic loop and continue-tools server. Error: Request failed with status code 404",
      "errorType": "tool_not_called",
      "context": {
        "query": "{\"name\":\"AlwaysStreamingMiddleware\",\"rule\":\"Use a dedicated `StreamMiddleware` class for non-blocking SSE streaming from backend to IDE. Always set SSE headers (`Content-Type: text/event-stream`) and handle errors gracefully.\",\"alwaysApply\":true}",
        "queryHash": "7df2d730",
        "expectedBehavior": "Tool should be available in agentic loop or MCP server",
        "actualBehavior": "Tool create_rule_block not found anywhere",
        "conversationLength": 1
      },
      "resolved": false,
      "pattern": "TOOL_SUPPRESSION"
    },
    {
      "id": "fail_1766798690203_202f49c1",
      "timestamp": "2025-12-27T01:24:50.203Z",
      "modelId": "cognitive-engine",
      "category": "tool",
      "tool": "edit_tool",
      "error": "Tool 'edit_tool' not available. Tried agentic loop and continue-tools server. Error: Request failed with status code 404",
      "errorType": "tool_not_called",
      "context": {
        "query": "{\"tool\":\"create_new_file\",\"filepath\":\"server/src/modules/tooly/streaming-middleware.ts\",\"contents\":\"// Enhanced Streaming Middleware for Non-Blocking SSE from Backend to IDE\\n//\\nexport class StreamMiddleware {\\n  private res: any;\\n  private isStreamingEnabled: boolean = true;\\n  \\n  constructor(res: any, isStreamingEnabled: boolean = true) {\\n    this.res = res;\\n    this.isStreamingEnabled = isStreamingEnabled;\\n    \\n    // Set SSE headers if streaming is enabled\\n    if (this.isStreamingEnabled) {\\n      res.setHeader('Content-Type', 'text/event-stream');\\n      res.setHeader('Cache-Control', 'no-cache');\\n      res.setHeader('Connection', 'keep-alive');\\n    }\\n  }\\n  \\n  // Send a chunk of data safely\\n  sendChunk(chunk: any): void {\\n    try {\\n      if (!this.res.headersSent) {\\n        this.res.write(`data: ${JSON.stringify(chunk)}\\n\\n`);\\n      }\\n    } catch (error) {\\n      console.error('Failed to send chunk:', error.message);\\n    }\\n  }\\n  \\n  // End the stream gracefully\\n  endStream(message?: string): void {\\n    try {\\n      if (!this.res.headersSent) {\\n        this.res.write(`data: [DONE] ${message || 'Stream ended'}\\n\\n`);\\n        this.res.end();\\n      }\\n    } catch (error) {\\n      console.error('Failed to end stream:', error.message);\\n    }\\n  }\\n  \\n  // Send an error safely\\n  sendError(message: string): void {\\n    try {\\n      if (!this.res.headersSent) {\\n        this.sendChunk({ type: 'error', message });\\n        this.endStream();\\n      }\\n    } catch (error) {\\n      console.error('Failed to send error:', error.message);\\n    }\\n  }\\n}\\n\\n// Example middleware integration for tool execution:\\nexport async function executeToolWithStreaming(res: any, isStreamingEnabled: boolean = true): Promise<void> {\\n  const streamer = new StreamMiddleware(res, isStreamingEnabled);\\n  \\n  // Simulate a tool execution with streaming updates\\n  streamer.sendChunk({ status: 'thinking', message: 'Processing request...' });\\n  await new Promise(resolve => setTimeout(resolve, 1000)); // Simulate delay\\n  streamer.sendChunk({ status: 'complete', content: 'Tool result received!' });\\n  \\n  streamer.endStream();\\n}\"}",
        "queryHash": "b20794aa",
        "expectedBehavior": "Tool should be available in agentic loop or MCP server",
        "actualBehavior": "Tool edit_tool not found anywhere",
        "conversationLength": 1
      },
      "resolved": false,
      "pattern": "TOOL_SUPPRESSION"
    }
  ],
  "patterns": {
    "TOOL_SUPPRESSION": {
      "id": "TOOL_SUPPRESSION",
      "name": "Tool Not Called When Needed",
      "description": "Model should call a tool but responds with text instead",
      "category": "tool",
      "count": 21,
      "firstSeen": "2025-12-27T00:28:25.015Z",
      "lastSeen": "2025-12-27T01:24:50.203Z",
      "examples": [
        "fail_1766795305015_fffddd6c",
        "fail_1766795308334_14ab803a",
        "fail_1766795309267_2590254c",
        "fail_1766795313121_896aef38",
        "fail_1766796451502_1c623db1",
        "fail_1766796885273_a86c7874",
        "fail_1766798135160_8513b692",
        "fail_1766798135165_ca3b1923",
        "fail_1766798227675_32c00b15",
        "fail_1766798232513_d739d476"
      ],
      "severity": "high"
    }
  },
  "stats": {
    "totalFailures": 21,
    "resolvedFailures": 0,
    "lastUpdated": "2025-12-27T01:24:50.203Z",
    "failuresByCategory": {
      "tool": 21,
      "rag": 0,
      "reasoning": 0,
      "intent": 0,
      "browser": 0,
      "unknown": 0
    },
    "failuresByModel": {
      "cognitive-engine": 21
    }
  }
}
