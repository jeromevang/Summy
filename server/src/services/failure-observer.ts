/**
 * Failure Observer Service
 * Monitors failures in real-time and broadcasts alerts via WebSocket.
 * 
 * Responsibilities:
 * - Group failures by pattern
 * - Detect threshold breaches (5+ similar failures)
 * - Broadcast notifications to connected clients
 * - Trigger controller analysis suggestions
 */

import { wsBroadcast } from './ws-broadcast.js';
import { failureLog } from './failure-log/FailureLogService.js';
import type { FailureEntry } from './failure-log/types.js';

// ============================================================
// TYPES
// ============================================================

/**
 * Represents a single failure alert generated by the observer.
 */
export interface FailureAlert {
  /** A unique identifier for the alert. */
  id: string;
  /** The type of event that triggered the alert. */
  type: 'threshold_breach' | 'critical_pattern' | 'new_pattern' | 'recurring_failure';
  /** The severity level of the alert. */
  severity: 'info' | 'warning' | 'error' | 'critical';
  /** The identifier of the failure pattern associated with the alert. */
  pattern: string;
  /** The user-friendly name of the failure pattern. */
  patternName: string;
  /** The count of failures matching the pattern at the time of alert. */
  count: number;
  /** Optional identifier for the model associated with the failure. */
  modelId?: string;
  /** A descriptive message about the alert. */
  message: string;
  /** The ISO 8601 timestamp when the alert was generated. */
  timestamp: string;
  /** Indicates if an action is required in response to the alert. */
  actionRequired: boolean;
  /** Optional suggested action to resolve the issue. */
  suggestedAction?: string;
}

/**
 * Configuration options for the FailureObserver.
 */
export interface ObserverConfig {
  /** Alert after N failures of the same pattern. */
  thresholdCount: number;
  /** Alert for critical patterns after N failures. */
  criticalThreshold: number;
  /** How often, in milliseconds, to check for new patterns and breaches. */
  checkIntervalMs: number;
  /** Whether the observer is enabled. */
  enabled: boolean;
}

// ============================================================
// FAILURE OBSERVER CLASS
// ============================================================

/**
 * Monitors failure logs for patterns and triggers alerts based on predefined rules.
 */
class FailureObserver {
  private config: ObserverConfig;
  private alertHistory: FailureAlert[] = [];
  private lastCheckTime: string = new Date().toISOString();
  private checkInterval: NodeJS.Timeout | null = null;
  private seenPatterns: Set<string> = new Set();

  /**
   * Initializes the FailureObserver with optional configuration.
   * @param config - Optional configuration to override default settings.
   */
  constructor(config?: Partial<ObserverConfig>) {
    this.config = {
      thresholdCount: 5,
      criticalThreshold: 3,
      checkIntervalMs: 30000, // 30 seconds
      enabled: true,
      ...config
    };
  }

  /**
   * Starts the failure monitoring process.
   * If enabled, it performs an initial check and then sets up periodic checks.
   */
  start(): void {
    if (this.checkInterval) {
      this.stop();
    }

    if (!this.config.enabled) {
      console.log('[FailureObserver] Observer is disabled');
      return;
    }

    console.log(`[FailureObserver] Starting observer (interval: ${this.config.checkIntervalMs}ms)`);
    
    // Initial check
    this.checkForAlerts();

    // Periodic checks
    this.checkInterval = setInterval(() => {
      this.checkForAlerts();
    }, this.config.checkIntervalMs);
  }

  /**
   * Stops the failure monitoring process.
   */
  stop(): void {
    if (this.checkInterval) {
      clearInterval(this.checkInterval);
      this.checkInterval = null;
      console.log('[FailureObserver] Observer stopped');
    }
  }

  /**
   * Updates the observer's configuration and restarts monitoring if necessary.
   * @param config - Partial configuration object to update.
   */
  configure(config: Partial<ObserverConfig>): void {
    this.config = { ...this.config, ...config };
    
    if (config.enabled !== undefined || config.checkIntervalMs !== undefined) {
      this.stop();
      if (this.config.enabled) {
        this.start();
      }
    }
  }

  /**
   * Handles a newly logged failure entry. Checks for critical pattern breaches.
   * This method is intended to be called when a new failure is logged.
   * @param entry - The FailureEntry that was just logged.
   */
  onFailureLogged(entry: FailureEntry): void { // Corrected parameter name
    if (entry.pattern) {
      const pattern = failureLog.getPattern(entry.pattern);
      if (pattern && pattern.severity === 'critical' && pattern.count >= this.config.criticalThreshold) {
        this.emitAlert({
          type: 'critical_pattern',
          severity: 'critical',
          pattern: pattern.id,
          patternName: pattern.name,
          count: pattern.count,
          modelId: entry.modelId,
          message: `Critical failure pattern detected: ${pattern.name}`, // Added missing message
          actionRequired: true,
          suggestedAction: 'Run controller analysis immediately'
        });
      }
    }
  }

  /**
   * Periodically checks all failure patterns against configured thresholds and emits alerts.
   * This is the core of the observer's monitoring loop.
   */
  private checkForAlerts(): void {
    const patterns = failureLog.getPatternsAboveThreshold(1); // Get all patterns
    const now = new Date().toISOString();

    for (const pattern of patterns) {
      // Check for threshold breaches
      if (pattern.count >= this.config.thresholdCount) {
        const alertId = `threshold_${pattern.id}`;
        
        if (!this.hasRecentAlert(alertId)) {
          this.emitAlert({
            type: 'threshold_breach',
            severity: pattern.severity === 'critical' ? 'critical' : 'warning',
            pattern: pattern.id,
            patternName: pattern.name,
            count: pattern.count,
            message: `${pattern.count} failures match pattern: ${pattern.name}`, // Added missing message
            actionRequired: pattern.count >= this.config.thresholdCount * 2,
            suggestedAction: pattern.count >= this.config.thresholdCount * 2 
              ? 'Consider running controller analysis'
              : undefined
          });
        }
      }

      // Check for new patterns (and alert if seen for the first time with count >= 2)
      if (!this.seenPatterns.has(pattern.id) && pattern.count >= 2) {
        this.seenPatterns.add(pattern.id);
        
        this.emitAlert({
          type: 'new_pattern',
          severity: 'info',
          pattern: pattern.id,
          patternName: pattern.name,
          count: pattern.count,
          message: `New failure pattern identified: ${pattern.name}`,
          actionRequired: false
        });
      }
    }

    // Check for recurring failures on same model
    const stats = failureLog.getStats();
    for (const [modelId, count] of Object.entries(stats.failuresByModel)) {
      if (count >= 10 && !this.hasRecentAlert(`recurring_${modelId}`)) {
        this.emitAlert({
          type: 'recurring_failure',
          severity: 'warning',
          pattern: 'MODEL_FAILURES',
          patternName: 'Recurring Model Failures',
          count,
          modelId,
          message: `Model ${modelId} has ${count} failures`,
          actionRequired: true,
          suggestedAction: 'Consider running smoke test or applying prosthetic'
        });
      }
    }

    this.lastCheckTime = now;
  }

  /**
   * Emits an alert to connected clients via WebSocket.
   * @param params - The parameters for the failure alert.
   */
  private emitAlert(params: Omit<FailureAlert, 'id' | 'timestamp'>): void {
    const alert: FailureAlert = {
      id: `alert_${Date.now()}_${Math.random().toString(36).substring(7)}`,
      timestamp: new Date().toISOString(),
      ...params
    };

    this.alertHistory.push(alert);

    // Keep only last 100 alerts
    if (this.alertHistory.length > 100) {
      this.alertHistory = this.alertHistory.slice(-100);
    }

    // Broadcast via WebSocket
    wsBroadcast.broadcast('failure_alert', alert);

    console.log(`[FailureObserver] Alert: ${alert.message} (${alert.severity})`);
  }

  /**
   * Checks if an alert for the given pattern key has been recently issued (within the last hour).
   * @param patternKey - The unique key identifying the failure pattern or model.
   * @returns True if a recent alert exists, false otherwise.
   */
  private hasRecentAlert(patternKey: string): boolean {
    const oneHourAgo = new Date(Date.now() - 60 * 60 * 1000).toISOString();
    
    return this.alertHistory.some(alert => 
      alert.pattern === patternKey && alert.timestamp > oneHourAgo
    );
  }

  /**
   * Retrieves a list of recent failure alerts.
   * @param limit - The maximum number of alerts to return. Defaults to 20.
   * @returns An array of the most recent FailureAlert objects.
   */
  getAlerts(limit: number = 20): FailureAlert[] {
    return this.alertHistory.slice(-limit).reverse();
  }

  /**
   * Gets the current status of the failure observer.
   * @returns An object containing status information.
   */
  getStatus(): {
    enabled: boolean;
    running: boolean;
    lastCheck: string;
    alertCount: number;
    patternsTracked: number;
    config: ObserverConfig;
  } {
    return {
      enabled: this.config.enabled,
      running: this.checkInterval !== null,
      lastCheck: this.lastCheckTime,
      alertCount: this.alertHistory.length,
      patternsTracked: this.seenPatterns.size,
      config: this.config
    };
  }

  /**
   * Provides a summary of the current failure state for dashboard display.
   * @returns An object containing summary data.
   */
  getDashboardSummary(): {
    unresolvedFailures: number;
    criticalPatterns: number;
    modelsAffected: number;
    recentAlerts: FailureAlert[];
    needsAttention: boolean;
  } {
    const stats = failureLog.getStats();
    const patterns = failureLog.getPatterns();
    const criticalPatterns = patterns.filter((p: any) =>
      p.severity === 'critical' && p.count >= this.config.criticalThreshold
    ).length;

    return {
      unresolvedFailures: stats.unresolvedCount,
      criticalPatterns,
      modelsAffected: Object.keys(stats.failuresByModel).length,
      recentAlerts: this.alertHistory.slice(-5).reverse(),
      needsAttention: criticalPatterns > 0 || stats.unresolvedCount >= 20
    };
  }

  /**
   * Clears all historical failure alerts.
   */
  clearAlerts(): void {
    this.alertHistory = [];
    console.log('[FailureObserver] Alert history cleared');
  }

  /**
   * Resets the observer's internal state, including history and seen patterns.
   */
  reset(): void {
    this.alertHistory = [];
    this.seenPatterns.clear();
    this.lastCheckTime = new Date().toISOString();
    console.log('[FailureObserver] Observer state reset');
  }
}

// ============================================================
// SINGLETON INSTANCE
// ============================================================

/**
 * The singleton instance of the FailureObserver.
 */
export const failureObserver = new FailureObserver();

// Auto-start observer when module loads (in production)
// failureObserver.start();

export default failureObserver;
